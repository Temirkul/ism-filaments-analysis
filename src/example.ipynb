{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model initialization and weights\n",
    "You can download the weights from here: https://drive.google.com/file/d/1lmKaJmXEFfcDuQqh2k6sK5JmDDxmQGzE/view?usp=drive_link\n",
    "\n",
    "The Planck dataset can be downloaded from here: https://drive.google.com/drive/folders/1hE8Mf49Jlj5Jg44M1Om09-mKsNZKGGk3?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import UNet\n",
    "from dataset import ImagesAndMasksDataset\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_classes = 181\n",
    "path = \"../model_saves/\"  # path where the downloaded model weights are stored \n",
    "unet = UNet(num_classes=num_classes, apply_batch_norm=False).to(\"cpu\")\n",
    "\n",
    "unet.load_state_dict(torch.load(path)[\"model_state_dict\"])\n",
    "unet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dir = '../data/Rects/256_256_1_10_0_0_0_3.5rects_10000_output/train/imgs/'   \n",
    "train_mask_dir = '../data/Rects/256_256_1_10_0_0_0_3.5rects_10000_output/train/masks/'\n",
    "val_image_dir = '../data/Rects/256_256_1_10_0_0_0_3.5rects_10000_output/val/imgs/'\n",
    "val_mask_dir = '../data/Rects/256_256_1_10_0_0_0_3.5rects_10000_output/val/masks/'\n",
    "planck_image_dir = '../data/PlanckData/images'   # these are the actual images \n",
    "planck_mask_dir = '../data/PlanckData/masks'   # these are the binary masks obtained from the images \n",
    "planck_theta_dir = '../data/PlanckData/thetas'  # these are the correct angles \n",
    "herschel_image_dir = '../data/HerschelData/images'\n",
    "herschel_mask_dir = '../data/HerschelData/masks'\n",
    "herschel_theta_dir = '../data/HerschelData/thetas'\n",
    "\n",
    "batch_size = 16 \n",
    "\n",
    "train_dataset = ImagesAndMasksDataset(train_image_dir, train_mask_dir)\n",
    "val_dataset = ImagesAndMasksDataset(val_image_dir, val_mask_dir)\n",
    "planck_images_dataset = ImagesAndMasksDataset(planck_image_dir, planck_theta_dir)\n",
    "planck_masks_dataset = ImagesAndMasksDataset(planck_mask_dir, planck_theta_dir)\n",
    "herschel_images_dataset = ImagesAndMasksDataset(herschel_image_dir, herschel_theta_dir)\n",
    "herschel_masks_dataset = ImagesAndMasksDataset(herschel_mask_dir, herschel_theta_dir)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "planck_images_dataloader = DataLoader(dataset=planck_images_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "planck_masks_dataloader = DataLoader(dataset=planck_masks_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "herschel_images_dataloader = DataLoader(dataset=herschel_images_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "herschel_masks_dataloader = DataLoader(dataset=herschel_masks_dataset, batch_size=batch_size, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_masks(unet: UNet, images: torch.Tensor) -> torch.Tensor:  # TODO: move this to utils.py\n",
    "    unet_raw_masks = unet(images)  # images are of shape [N, C, H, W]\n",
    "    unet_masks = torch.argmax(unet_raw_masks, dim=1)\n",
    "    return unet_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 30\n",
    "images, masks = next(iter(val_dataloader))\n",
    "print(\"IMG SHAPE \", images.shape, np.unique(images))\n",
    "print(\"MASK SHAPE \", masks.shape)\n",
    "\n",
    "unet_masks = get_unet_masks(unet, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, batch_size//2, figsize=(size,size))\n",
    "for i in range(batch_size//2):\n",
    "    axs[0, i].imshow(images[i,0,:,:], cmap=\"gray\", vmin=0, vmax=1)\n",
    "    im = axs[1, i].imshow(masks[i,:,:], cmap=\"jet\", vmin=0, vmax=180)\n",
    "    axs[2, i].imshow(unet_masks, cmap=\"jet\", vmin=0, vmax=180)\n",
    "cbax = fig.add_axes([0.91, 0.4529, 0.01, 0.1])\n",
    "fig.colorbar(im, cax=cbax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on real data\n",
    "On real data, images need to be preprocessed first to get good performance. \n",
    "Ideally, we should preprocess the images in a way s.t. the final resulting images are binary images filled with 0 or 1 pixel values.\n",
    "However, if the resulting images are close enough to being binary (image mean $\\approx$ 1), then that works too.\n",
    "The reason why this is required is because the training data consists of binary images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_planck, masks_planck = next(iter(planck_images_dataloader))\n",
    "fig, axs = plt.subplots(1, batch_size, figsize=(size,size))\n",
    "for i in range(batch_size):\n",
    "    axs[i].imshow(images_planck[i,0,:,:], cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_planck_np = (images_planck*255).detach().cpu().numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING\n",
    "\n",
    "images_morph = np.zeros((16, 256, 256))\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "for i in range(images_planck_np.shape[0]):\n",
    "    images_morph[i, :, :] = cv2.morphologyEx(images_planck_np[i, 0, :, :], cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "images_morph = images_morph/np.max(images_morph) * 255\n",
    "print(np.max(images_morph), np.average(images_morph))\n",
    "\n",
    "images_morph_2 = np.zeros((16, 256, 256))\n",
    "kernel_2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "for i in range(images_planck_np.shape[0]):\n",
    "    images_morph_2[i, :, :] = cv2.dilate(cv2.morphologyEx(images_morph[i, :, :], cv2.MORPH_OPEN, kernel_2, iterations=1), kernel_2, iterations=1)\n",
    "print(np.max(images_morph_2), np.average(images_morph_2), np.min(images_morph_2))\n",
    "\n",
    "fig, axs = plt.subplots(3, batch_size, figsize=(size,size))\n",
    "for i in range(batch_size):\n",
    "    axs[0, i].imshow(images[i,0,:,:], cmap='gray', vmin=0, vmax=1)  \n",
    "    axs[1, i].imshow(images_morph[i,:,:], cmap='gray', vmin=0, vmax=10)\n",
    "    axs[2, i].imshow(images_morph_2[i,:,:], cmap='gray', vmin=0, vmax=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_masks = get_unet_masks(unet, torch.from_numpy(images_morph_2).to(torch.float32).unsqueeze(1))\n",
    "\n",
    "print(torch.mean(images), torch.max(images))\n",
    "\n",
    "fig, axs = plt.subplots(2, batch_size, figsize=(size,size-25))\n",
    "for i in range(batch_size):\n",
    "    axs[0, i].imshow(images[i,0,:,:], cmap='gray', vmin=0, vmax=1)\n",
    "    im = axs[1, i].imshow(unet_masks[i,:,:].to(torch.float32), cmap='jet', vmin=0, vmax=180)  \n",
    "cbax = fig.add_axes([0.91, 0.1529, 0.01, 0.4])\n",
    "fig.colorbar(im, cax=cbax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
